{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-63ihZ8ufu6T"
      },
      "source": [
        "#<font color='#2ecc71' > Co-Occurence Matrix <br> Frequency-based Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iVlh07i8Ba8p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "import itertools\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efPLueoKhVAM"
      },
      "source": [
        "###<font color='#2ecc71' > Define function to loop through bigrams - recording the current and next words. <br> Then calculate the number of occurences of the bigram. <br> [NLTK probability Module](http://www.nltk.org/api/nltk.html?highlight=freqdist) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7eNCzSwFkf2X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'banana', 'apple', 'cherry'}\n"
          ]
        }
      ],
      "source": [
        "x = set((\"apple\", \"banana\", \"cherry\"))\n",
        "\n",
        "print(x)\n",
        "\n",
        "#The set() function creates a set object.\n",
        "\n",
        "#The items in a set list are unordered, so it will appear in random order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXzfvRv3BXUY"
      },
      "outputs": [],
      "source": [
        "def generate_co_occurrence_matrix(corpus):\n",
        "    vocab = set(corpus)\n",
        "    vocab = list(vocab)\n",
        "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
        " \n",
        "    # Create bigrams from all words in corpus\n",
        "    bi_grams = list(bigrams(corpus))\n",
        " \n",
        "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
        "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
        " \n",
        "    # Initialise co-occurrence matrix\n",
        "    # co_occurrence_matrix[current][previous]\n",
        "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
        " \n",
        "    # Loop through the bigrams taking the current and previous word,\n",
        "    # and the number of occurrences of the bigram.\n",
        "    for bigram in bigram_freq:\n",
        "        current = bigram[0][1]\n",
        "        previous = bigram[0][0]\n",
        "        count = bigram[1]\n",
        "        pos_current = vocab_index[current]\n",
        "        pos_previous = vocab_index[previous]\n",
        "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
        "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
        " \n",
        "    # return the matrix and the index\n",
        "    return co_occurrence_matrix, vocab_index\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tod2doQrmkXy"
      },
      "source": [
        "The FreqDist class is used to encode “frequency distributions”, which count the number of times that each outcome of an experiment occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PSbmjThmjXd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb12n_aRgbha"
      },
      "source": [
        "#<font color='#2ecc71' > Create Dataframe & Calculate Similariry Scores Between 2 Words - Pass Corpus Into Function Defined Above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKTLZohPBgt2",
        "outputId": "04ec3ae6-670b-495c-8321-3e26ada03e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         earned  penny  saved   is    a  wise  foolish\n",
            "earned      0.0    1.0    0.0  0.0  0.0   0.0      0.0\n",
            "penny       0.0    0.0    0.0  0.0  2.0   1.0      0.0\n",
            "saved       0.0    1.0    0.0  0.0  0.0   0.0      0.0\n",
            "is          0.0    0.0    1.0  0.0  0.0   0.0      0.0\n",
            "a           0.0    0.0    0.0  1.0  0.0   0.0      1.0\n",
            "wise        0.0    1.0    0.0  0.0  0.0   0.0      0.0\n",
            "foolish     0.0    1.0    0.0  0.0  0.0   0.0      0.0\n"
          ]
        }
      ],
      "source": [
        "corpus = [['penny', 'wise', 'penny', 'foolish'],\n",
        "             ['a', 'penny', 'saved', 'is', 'a','penny','earned']]\n",
        " \n",
        "# Create one list using many lists\n",
        "mylist = list(itertools.chain.from_iterable(corpus))\n",
        "matrix, vocab_index = generate_co_occurrence_matrix(mylist)\n",
        " \n",
        " \n",
        "co_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
        "                             columns=vocab_index)\n",
        "print(co_matrix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Complete_Co-OccurenceMatrix.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
