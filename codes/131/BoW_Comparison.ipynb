{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBGPbXPIb2Gr"
      },
      "source": [
        "##<font color='#12CBC4'> Comparison Between BoW & Word Embeddings In Detecting Simiarlity & Context<br>Semantic similarity between two words, phrases or even two documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AN0upTx_XGyj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting en_core_web_lg==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz (782.7 MB)\n",
            "     |████████████████████████████████| 782.7 MB 1.3 MB/s              |██████████████████████████████▌ | 746.8 MB 1.3 MB/s eta 0:00:28  |██████████████████████████████▊ | 751.0 MB 1.3 MB/s eta 0:00:24  MB 1.3 MB/s eta 0:00:15  MB 1.3 MB/s eta 0:00:12  MB 1.3 MB/s eta 0:00:06 \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from en_core_web_lg==2.3.1) (2.3.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.22.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (45.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/shakabrah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "!python3 -m spacy download en_core_web_lg\n",
        "#language model\n",
        "import en_core_web_lg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ptgQ3qVxawfR"
      },
      "outputs": [],
      "source": [
        "# !pip3 install -U spacy\n",
        "#!python3 -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG99BAA0bTzI"
      },
      "source": [
        "##<font color='#12CBC4'>Calculate Similarity Scores With spaCy and BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZD1SDeqjW_7P"
      },
      "outputs": [],
      "source": [
        "#code to calculate spaCy and BoW similarity scores from two texts\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\") \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8cgXqA2gcp6"
      },
      "source": [
        "##<font color='#12CBC4'> Spacy Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "text1 = 'In 1919 there was the Spanish Flu'\n",
        "text2 = 'Covid-19 hit the entire world in 2020 and became a pandemic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM0E8zGhgLdJ",
        "outputId": "4070f549-0964-4aa9-c3d4-6793fb5ae50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spaCy similarity: 0.8164648653089354\n"
          ]
        }
      ],
      "source": [
        "#Calculates spaCy similarity between texts 1 and 2\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "print(\"spaCy similarity:\", doc1.similarity(doc2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMDYQB6ggTF"
      },
      "source": [
        "##<font color='#12CBC4'>BoW Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI683ZvYgWH5",
        "outputId": "c6aa584b-06c0-4725-ad37-1442359e8a8a"
      },
      "outputs": [],
      "source": [
        "#Calculate cosine similarity using Bag-of-Words \n",
        "documents =[text1, text2]\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), index=['x', 'y'])\n",
        "print(\"Cosine similarity:\", cosine_similarity(df, df)[0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7drqqb-kc3j6"
      },
      "source": [
        "<font color='#B53471'>Spacy Notes<br>3 types of word objects in spacy; (1) docs (2) tokens and (3) spans. Docs refer to doc objects made from texts analogous to paragraphs or full documents; while tokens refer to word like chunks which represents the most atomic parts of a doc. spans are continuous list of these tokens; i.e. analogue of a phrase.<br>spaCy md model, which has a relatively small number of vectors (between 10k and 20k), and other tokens mapped to their nearest vector<br>If you try to calculate simiarity using Spacy Small Language Model, you get a warning - bcause no real vector is loaded and the similarity measure is created using ner and pos taggers and similar signs.<br>\n",
        "<br><font color='#FFC312'>The small model basically checks to see the the same words reappear. <font color='#B53471'>The reason behind this is that to optimize the memory usage, spacy doesn't load any real word embedding for the vocabulary it uses when it loads the smaller models. \n",
        "\n",
        "<font color='#B53471'>spaCy uses word vectors for medium (md) and large (lg). Therefore, to use the actual vectors and get better accuracy, use either the medium model i.e. en_core_web_md or the large model i.e. en_core_web_lg. The large model contains a very large vocabulary with unique vectors for more than a million words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDp5DQwqa9Uo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BoW_Comparison.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
